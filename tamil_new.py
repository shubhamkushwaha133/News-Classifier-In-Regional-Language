# -*- coding: utf-8 -*-
"""Tamil_NEW.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gn2kGRON045ah-0i5KfLBxYwLWNuHVwo
"""

!pip install gradio

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
new_data = pd.read_csv('drive/MyDrive/Colab Notebooks/tamilmurasu_dataset.csv')
#new_data = pd.read_csv('drive/MyDrive/Colab Notebooks/tamilmurasu_dataset.csv').head(15000)


categories = new_data['news_category'].unique()

print("Unique News Categories:")
for category in categories:
    print(f"{category}")

print(new_data.columns)


new_data

"""# **LSTM**"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import LSTM, Dense, Embedding, SpatialDropout1D
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.utils import to_categorical

# Load the dataset
data = pd.read_csv('drive/MyDrive/Colab Notebooks/tamilmurasu_dataset.csv')

# Preprocessing
# 1. Convert category labels to numerical values
category_mapping = {'மர்மம்': 1, 'இந்தியா': 2, 'விளையாட்டு': 3, 'ஆன்மீகம்': 4, 'தொழில்': 5, 'சினிமா(ரீல்மா)': 6,
                    'உலகம்': 7, 'கல்வி': 8, 'குற்றம்': 9, 'ஸ்டேட் எக்ஸ்பிரஸ்': 10, 'தலையங்கம்': 11, 'மாவட்ட மசாலா': 12,
                    'தமிழகம்': 13, 'வேலைவாய்ப்பு': 14, 'மருத்துவம்': 15}
data['news_category'] = data['news_category'].replace(category_mapping)

# 2. Tokenization and padding
MAX_NB_WORDS = 5000  # Maximum number of words in the vocabulary
MAX_SEQUENCE_LENGTH = 250  # Maximum length of each news article
EMBEDDING_DIM = 100  # Dimension of the word embeddings

tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!"#$%&()*+,-./:;<=>?@[\]^_`{|}~', lower=True)
tokenizer.fit_on_texts(data['news_article'])
word_index = tokenizer.word_index
X = tokenizer.texts_to_sequences(data['news_article'])
X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)

# 3. Splitting the dataset into training and testing sets
Y = to_categorical(data['news_category'])
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Model Architecture
model = Sequential()
model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))
model.add(SpatialDropout1D(0.2))
model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(16, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Training the model
epochs = 5
batch_size = 64
history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, Y_test))

# Evaluate the model
train_accuracy = history.history['accuracy']
print('Training Accuracy:', train_accuracy[-1])

score = model.evaluate(X_test, Y_test, verbose=0)
print('Test accuracy:', score[1])



from keras.models import load_model
# Save the trained model
model.save('drive/MyDrive/Colab/New_lstm_model.keras')

from keras.models import load_model
from sklearn.metrics import classification_report

# Load the trained model
model = load_model('drive/MyDrive/Colab/New_lstm_model.keras')

# Make predictions
predictions = model.predict(X_test)

# Generate classification report
predicted_classes = np.argmax(predictions, axis=1)
true_classes = np.argmax(Y_test, axis=1)

# Define reverse mapping dictionary for English category labels
category_mapping_reverse = {
    1: 'Mystery',
    2: 'India',
    3: 'Sports',
    4: 'Spiritual',
    5: 'Business',
    6: 'Cinema(Real)',
    7: 'World',
    8: 'Education',
    9: 'Crime',
    10: 'State Express',
    11: 'Headline',
    12: 'District Masala',
    13: 'Tamil Nadu',
    14: 'Employment',
    15: 'Medicine'
}

# Generate classification report using English category labels
report = classification_report(true_classes, predicted_classes, target_names=category_mapping_reverse.values(), zero_division=1)

# Print the classification report
print("Classification Report:")
print(report)

import numpy as np
from keras.preprocessing.sequence import pad_sequences
from keras.models import load_model
import gradio as gr

# Load the pre-trained LSTM model
model = load_model('drive/MyDrive/Colab/New_lstm_model.keras')

# Define reverse mapping dictionary for English category labels
category_mapping_reverse = {
    1: 'Mystery',
    2: 'India',
    3: 'Sports',
    4: 'Spiritual',
    5: 'Business',
    6: 'Cinema',
    7: 'World',
    8: 'Education',
    9: 'Crime',
    10: 'State Express',
    11: 'Headline',
    12: 'District Masala',
    13: 'Tamil Nadu',
    14: 'Employment',
    15: 'Medicine'
}

max_sequence_length = 250

# Preprocess the Tamil news text
def preprocess_tamil_news(text):
    # Tokenize the text
    tokens = tokenizer.texts_to_sequences([text])
    # Pad sequences to fixed length
    padded_tokens = pad_sequences(tokens, maxlen=max_sequence_length)
    return padded_tokens

# Define the function to predict the category
def predict_category(tamil_news_text):
    # Preprocess the Tamil news text
    preprocessed_news = preprocess_tamil_news(tamil_news_text)
    # Make predictions
    predicted_category = model.predict(preprocessed_news)
    # Map the predicted category label to English category name
    predicted_category_name = category_mapping_reverse[np.argmax(predicted_category)]
    return predicted_category_name

# Define Gradio interface
iface = gr.Interface(fn=predict_category, inputs="text", outputs="text", title="Tamil News Category Prediction",
                     description="Enter a Tamil news headline and find its category in English.")
iface.launch()


#test news

# சென்னையில் வெள்ளம் கட்டுக்குள் வரவில்லை                                  Floods in Chennai are not under control
# சென்னையில் பெண் கொல்லப்பட்டார்                                           Woman killed in Chennai ....
# டெல்லியில் பூகம்பம்                                                            Earthquake in Delhi
# நடிகர் போதைப்பொருள் பயன்படுத்தி பிடிபட்டார்                              The actor was caught using drugs
# கால்பந்து ரசிகர்களை இழந்து வருகிறது                                        Football is losing fans
# மலேசிய விமானம் காணவில்லை                                               Malaysia Airlines flight missing
# கிரிக்கெட் ஒரு விளையாட்டு                                                    cricket is a game
# சென்னை எனது மாநிலத்தின் தலைநகரம்                                      chennai is the capital of my state
# இன்றைய போட்டியில் தோனி 100 ரன்கள் எடுத்தார்                            today dhoni scored 100 runs in the match
# கால்பந்து மேற்கத்திய நாடுகளில் பிரபலமானது                                football is famous in western countries
# அக்ஷய் ஒரு பிரபலமான ஹீரோ                                                Akshay is a famous hero
# தொலைக்காட்சி நிகழ்ச்சியில் சல்மான் நடிக்கிறார்                             salman  is playing a role in tv show
# டெல்லி நம் நாட்டின் தலைநகரம்                                                delhi is the capital of our country
# கிரிக்கெட் இந்தியாவில் பிரபலமானது                                           cricket is popular in india
# கிரிக்கெட் இங்கு பிரபலம்                                                       cricket is popular here
# சென்னை துறைமுகத்தில் போர்க் கப்பல்களை பார்வையிட  மாணவர்களுக்கு அனுமதி        Students are allowed to visit the warships in Chennai harbour 101
# மதுரை ஏர்போர்ட்டுக்கு 'சுங்க அந்தஸ்து'                                            'Customs Status' for Madurai Airport
# ஹைதி முகாமில் அதிகரிக்கிறது பலாத்காரம்                                         Rape escalates in Haiti camp
# முகத்தை ஸ்கேன் பண்ணினா நடிகை வயசும் ‘நச்’னு தெரியும்                      If you scan the face, you will know the age of the actress
# மருந்து விலை அதிகம்                                                                medicine rates are high
# அரசாங்க அறிக்கைகளின்படி இந்தியாவில் மருத்துவர்கள் நன்றாகப் படிக்கவில்லை   Doctors in India are not well educated according to government reports
# அரசு அறிக்கைகளால் மருத்துவர்கள் நன்கு படித்தவர்கள் அல்ல                       Doctors are not well-educated by government reports

"""# **CNN**"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Embedding, Dropout
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.utils import to_categorical

# Load the dataset
data = pd.read_csv('drive/MyDrive/Colab Notebooks/tamilmurasu_dataset.csv')

# Preprocessing
# 1. Convert category labels to numerical values
category_mapping = {'மர்மம்': 1, 'இந்தியா': 2, 'விளையாட்டு': 3, 'ஆன்மீகம்': 4, 'தொழில்': 5, 'சினிமா(ரீல்மா)': 6,
                    'உலகம்': 7, 'கல்வி': 8, 'குற்றம்': 9, 'ஸ்டேட் எக்ஸ்பிரஸ்': 10, 'தலையங்கம்': 11, 'மாவட்ட மசாலா': 12,
                    'தமிழகம்': 13, 'வேலைவாய்ப்பு': 14, 'மருத்துவம்': 15}
data['news_category'] = data['news_category'].replace(category_mapping)

# 2. Tokenization and padding
MAX_NB_WORDS = 5000  # Maximum number of words in the vocabulary
MAX_SEQUENCE_LENGTH = 250  # Maximum length of each news article
EMBEDDING_DIM = 100  # Dimension of the word embeddings

tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!"#$%&()*+,-./:;<=>?@[\]^_`{|}~', lower=True)
tokenizer.fit_on_texts(data['news_article'])
word_index = tokenizer.word_index
X = tokenizer.texts_to_sequences(data['news_article'])
X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)

# 3. Splitting the dataset into training and testing sets
Y = to_categorical(data['news_category'])
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Model Architecture (CNN)
model = Sequential()
model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))
model.add(Conv1D(128, 5, activation='relu'))
model.add(MaxPooling1D(5))
model.add(Conv1D(128, 5, activation='relu'))
model.add(GlobalMaxPooling1D())
model.add(Dense(16, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Training the model
epochs = 5
batch_size = 64
history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, Y_test))

# Evaluate the model
train_accuracy = history.history['accuracy']
print('Training Accuracy:', train_accuracy[-1])

score = model.evaluate(X_test, Y_test, verbose=0)
print('Test accuracy:', score[1])


# Save the trained model
model.save('drive/MyDrive/Colab/New_cnn_model.keras')


import numpy as np
from keras.models import load_model
from sklearn.metrics import classification_report

# Load the trained CNN model
#model = load_model('drive/MyDrive/Colab/New_cnn_model.keras')

# Make predictions
predictions = model.predict(X_test)

# Generate classification report
predicted_classes = np.argmax(predictions, axis=1)
true_classes = np.argmax(Y_test, axis=1)

# Define reverse mapping dictionary for English category labels
category_mapping_reverse = {
    1: 'Mystery',
    2: 'India',
    3: 'Sports',
    4: 'Spiritual',
    5: 'Business',
    6: 'Cinema',
    7: 'World',
    8: 'Education',
    9: 'Crime',
    10: 'State Express',
    11: 'Headline',
    12: 'District Masala',
    13: 'Tamil Nadu',
    14: 'Employment',
    15: 'Medicine'
}

# Generate classification report using English category labels
report = classification_report(true_classes, predicted_classes, target_names=category_mapping_reverse.values(), zero_division=1)

# Print the classification report
print("Classification Report:")
print(report)

"""# **CNN LSTM Hybrid**"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Embedding, LSTM
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.utils import to_categorical

# Load the dataset
data = pd.read_csv('drive/MyDrive/Colab Notebooks/tamilmurasu_dataset.csv')

# Preprocessing
# 1. Convert category labels to numerical values
category_mapping = {'மர்மம்': 1, 'இந்தியா': 2, 'விளையாட்டு': 3, 'ஆன்மீகம்': 4, 'தொழில்': 5, 'சினிமா(ரீல்மா)': 6,
                    'உலகம்': 7, 'கல்வி': 8, 'குற்றம்': 9, 'ஸ்டேட் எக்ஸ்பிரஸ்': 10, 'தலையங்கம்': 11, 'மாவட்ட மசாலா': 12,
                    'தமிழகம்': 13, 'வேலைவாய்ப்பு': 14, 'மருத்துவம்': 15}
data['news_category'] = data['news_category'].replace(category_mapping)

# 2. Tokenization and padding
MAX_NB_WORDS = 5000  # Maximum number of words in the vocabulary
MAX_SEQUENCE_LENGTH = 250  # Maximum length of each news article
EMBEDDING_DIM = 100  # Dimension of the word embeddings

tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!"#$%&()*+,-./:;<=>?@[\]^_`{|}~', lower=True)
tokenizer.fit_on_texts(data['news_article'])
word_index = tokenizer.word_index
X = tokenizer.texts_to_sequences(data['news_article'])
X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)

# 3. Splitting the dataset into training and testing sets
Y = to_categorical(data['news_category'])
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Model Architecture (CNN-LSTM Hybrid)
model = Sequential()
model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))
model.add(Conv1D(128, 5, activation='relu'))
model.add(MaxPooling1D(5))
model.add(Conv1D(128, 5, activation='relu'))
model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(16, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Training the model
epochs = 5
batch_size = 64
history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, Y_test))

# Evaluate the model
train_accuracy = history.history['accuracy']
print('Training Accuracy:', train_accuracy[-1])

score = model.evaluate(X_test, Y_test, verbose=0)
print('Test accuracy:', score[1])


# Save the trained model
model.save('drive/MyDrive/Colab/New_cnn_lstm_hybrid_model.keras')

import numpy as np
from keras.models import load_model
from sklearn.metrics import classification_report

# Load the trained CNN model
model = load_model('drive/MyDrive/Colab/New_cnn_lstm_hybrid_model.keras')

# Make predictions
predictions = model.predict(X_test)

# Generate classification report
predicted_classes = np.argmax(predictions, axis=1)
true_classes = np.argmax(Y_test, axis=1)

# Define reverse mapping dictionary for English category labels
category_mapping_reverse = {
    1: 'Mystery',
    2: 'India',
    3: 'Sports',
    4: 'Spiritual',
    5: 'Business',
    6: 'Cinema',
    7: 'World',
    8: 'Education',
    9: 'Crime',
    10: 'State Express',
    11: 'Headline',
    12: 'District Masala',
    13: 'Tamil Nadu',
    14: 'Employment',
    15: 'Medicine'
}

# Generate classification report using English category labels
report = classification_report(true_classes, predicted_classes, target_names=category_mapping_reverse.values(), zero_division=1)

# Print the classification report
print("Classification Report:")
print(report)